{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bebc4425-f087-40eb-abba-795d201babb0",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation in Verba Notebook\n",
    "## Using Weaviate\n",
    "\n",
    "This notebook displays a small demo of how RAG works in Verba in its five stages: Reading, Chunking, Embedding, Retrieving, and Generating. Follow along the notebook to learn more! \n",
    "\n",
    "> (This demo uses the ADA model for the embeddings and GPT4-Turbo for generating the answer to the query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b27a1-bccd-48cb-9b55-00de6d96dad1",
   "metadata": {},
   "source": [
    "## Step 01 - Setup Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd462fe3-90b6-448d-a0d2-f9b33ee7bb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: weaviate-client in /Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages (3.25.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.30.0 in /Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages (from weaviate-client) (2.31.0)\n",
      "Requirement already satisfied: validators<1.0.0,>=0.21.2 in /Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages (from weaviate-client) (0.22.0)\n",
      "Requirement already satisfied: authlib<2.0.0,>=1.2.1 in /Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages (from weaviate-client) (1.2.1)\n",
      "Requirement already satisfied: cryptography>=3.2 in /Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (41.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2023.11.17)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages (from cryptography>=3.2->authlib<2.0.0,>=1.2.1->weaviate-client) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.2->authlib<2.0.0,>=1.2.1->weaviate-client) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11fc83c7-225b-426b-9722-20830042eda9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /Users/edwardschmuhl/.cache/weaviate-embedded: process ID 50578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2023-11-20T17:42:13+01:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2023-11-20T17:42:13+01:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"document_oL4j0epV7Dcm\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-11-20T17:42:13+01:00\",\"took\":40333}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2023-11-20T17:42:13+01:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"chunk_z5kv7UEkQOX5\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-11-20T17:42:13+01:00\",\"took\":1678958}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2023-11-20T17:42:13+01:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2023-11-20T17:42:13+01:00\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "\n",
    "# Setup Weaviate Embedded (runs locally)\n",
    "client = weaviate.Client(\n",
    "                additional_headers={\"X-OpenAI-Api-Key\": os.environ.get(\"OPENAI_API_KEY\", \"\")},\n",
    "                embedded_options=EmbeddedOptions(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba59802-bfaa-44df-a9c3-c3bdd73367dd",
   "metadata": {},
   "source": [
    "## Step 02 - Setup Classes\n",
    "For our little RAG demo we'll create a Document and Chunk class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f4745a-509c-4609-96e2-9f5e311c09a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk\n",
      "Document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"chunk_ysfbygP4DYw2\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-11-20T17:42:22+01:00\",\"took\":71042}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"document_nfurcsnAZkbc\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-11-20T17:42:22+01:00\",\"took\":87291}\n"
     ]
    }
   ],
   "source": [
    "# Check if client is ready, and clear all data\n",
    "if client.is_ready():\n",
    "    client.schema.delete_all()\n",
    "\n",
    "SCHEMA_CHUNK = {\n",
    "        \"classes\": [\n",
    "            {\n",
    "                \"class\": \"Chunk\",\n",
    "                \"vectorizer\": \"text2vec-openai\",\n",
    "                \"moduleConfig\": { \n",
    "                   \"generative-openai\": { \n",
    "                        \"model\": \"gpt-4-1106-preview\", \n",
    "                    }\n",
    "                },\n",
    "                \"description\": \"Chunks of Documentations\",\n",
    "                \"properties\": [\n",
    "                    {\n",
    "                        \"name\": \"text\",\n",
    "                        \"dataType\": [\"text\"],\n",
    "                        \"description\": \"Content of the document\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"doc_uuid\",\n",
    "                        \"dataType\": [\"text\"],\n",
    "                        \"description\": \"Document UUID\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"chunk_id\",\n",
    "                        \"dataType\": [\"number\"],\n",
    "                        \"description\": \"Document chunk from the whole document\",\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "SCHEMA_DOCUMENT = {\n",
    "        \"classes\": [\n",
    "            {\n",
    "                \"class\": \"Document\",\n",
    "                \"description\": \"Documentation\",\n",
    "                \"properties\": [\n",
    "                    {\n",
    "                        \"name\": \"text\",\n",
    "                        \"dataType\": [\"text\"],\n",
    "                        \"description\": \"Content of the document\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"doc_name\",\n",
    "                        \"dataType\": [\"text\"],\n",
    "                        \"description\": \"Document name\",\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "client.schema.create(SCHEMA_CHUNK)\n",
    "client.schema.create(SCHEMA_DOCUMENT)\n",
    "for _class in client.schema.get()[\"classes\"]:\n",
    "    print(_class[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3508746-d906-41d5-92b4-33bb1d677134",
   "metadata": {},
   "source": [
    "## Step 03 - Load PDF to Python (Reading)\n",
    "We're importing the paper: \"Attention is all you need\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf3396-4710-4996-a1ba-589f35b3abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25ba8c9-89a8-46c3-9448-8c6528d6250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardschmuhl/Desktop/Work/Forks/verba_notebook/venv/lib/python3.10/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.comNoam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.comNiki Parma\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "full_text = \"\"\n",
    "reader = PdfReader(\"./data/attention_is_all_you_need.pdf\")\n",
    "\n",
    "for page in reader.pages:\n",
    "    full_text += page.extract_text() + \"\\n\\n\"\n",
    "\n",
    "document = { \"text\":full_text, \"doc_name\": \"Attention_Is_All_You_Need\", \"chunks\":[] }\n",
    "\n",
    "print(document[\"text\"][100:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0616f9-025b-414d-8964-c837c8f17a83",
   "metadata": {},
   "source": [
    "## Step 04 - Chunk Document (Chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07a851-ca79-4d0c-abf4-7e3c14120eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "414b3fd2-eb86-4c26-88be-a4edb33fa9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "----FIRST CHUNK----\n",
      "{'text': ' recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes', 'chunk_id': 5}\n",
      "\n",
      "----SECOND CHUNK----\n",
      "{'text': ' WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer', 'chunk_id': 6}\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "units = 100\n",
    "overlap = 50\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "encoded_tokens = encoding.encode(document[\"text\"], disallowed_special=())\n",
    "\n",
    "document[\"chunks\"] = []\n",
    "\n",
    "i = 0\n",
    "split_id_counter = 0\n",
    "while i < len(encoded_tokens):\n",
    "    # Overlap\n",
    "    start_i = i\n",
    "    end_i = min(i + units, len(encoded_tokens))\n",
    "\n",
    "    chunk_tokens = encoded_tokens[start_i:end_i]\n",
    "    chunk_text = encoding.decode(chunk_tokens)\n",
    "\n",
    "    doc_chunk = {\"text\":chunk_text, \"chunk_id\":split_id_counter}\n",
    "    document[\"chunks\"].append(doc_chunk)\n",
    "    split_id_counter += 1\n",
    "\n",
    "    # Exit loop if this was the last possible chunk\n",
    "    if end_i == len(encoded_tokens):\n",
    "        break\n",
    "\n",
    "    i += units - overlap  # Step forward, considering overlap\n",
    "\n",
    "print(len(document[\"chunks\"]))\n",
    "print(\"----FIRST CHUNK----\")\n",
    "print(document[\"chunks\"][5])\n",
    "print(\"\")\n",
    "print(\"----SECOND CHUNK----\")\n",
    "print(document[\"chunks\"][6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485964b-679b-496f-90da-878b218cc27c",
   "metadata": {},
   "source": [
    "## Step 05 - Embed into Weaviate (Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7259043c-d7ae-4fbd-acff-22fa3f9cb1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done :)\n"
     ]
    }
   ],
   "source": [
    "with client.batch as batch:\n",
    "    batch.batch_size = 1\n",
    "    properties = {\n",
    "        \"text\": str(document[\"text\"]),\n",
    "        \"doc_name\": str(document[\"doc_name\"]),\n",
    "    }\n",
    "    \n",
    "    class_name = \"Document\"\n",
    "    uuid = client.batch.add_data_object(properties, class_name)\n",
    "    \n",
    "    for chunk in document[\"chunks\"]:\n",
    "        chunk[\"doc_uuid\"] = uuid\n",
    "\n",
    "\n",
    "with client.batch as batch:\n",
    "    batch.batch_size = len(document[\"chunks\"])\n",
    "    for i, chunk in enumerate(document[\"chunks\"]):\n",
    "\n",
    "        properties = {\n",
    "            \"text\": chunk[\"text\"],\n",
    "            \"doc_uuid\": chunk[\"doc_uuid\"],\n",
    "            \"chunk_id\": chunk[\"chunk_id\"],\n",
    "        }\n",
    "        class_name = \"Chunk\"\n",
    "        client.batch.add_data_object(properties, class_name)\n",
    "\n",
    "print(\"Done :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b40818-b8e0-46b5-a280-97c69dd19162",
   "metadata": {},
   "source": [
    "## Step 06 - Retrieve Chunks based on Query (Retrieving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "632c907e-e6ed-4d0a-a8bf-cd321d36bacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{'_additional': {'score': '0.75'}, 'chunk_id': 24, 'doc_uuid': 'bf38b308-172c-4394-9c32-16ee6c405682', 'text': '2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown'}\n"
     ]
    }
   ],
   "source": [
    "from weaviate.gql.get import HybridFusion\n",
    "\n",
    "query = \"What is attention?\"\n",
    "\n",
    "results = client.query.get(\n",
    "        class_name=\"Chunk\",\n",
    "        properties=[\n",
    "            \"text\",\n",
    "            \"chunk_id\",\n",
    "            \"doc_uuid\",\n",
    "        ]).with_additional(properties=[\"score\"]).with_autocut(2).with_hybrid(query=query,fusion_type=HybridFusion.RELATIVE_SCORE,properties=[\"text\"]).do()\n",
    "\n",
    "print(len(results[\"data\"][\"Get\"][\"Chunk\"]))\n",
    "print(results[\"data\"][\"Get\"][\"Chunk\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a875e4ff-4855-44cd-a9ed-efc7bb3b2613",
   "metadata": {},
   "source": [
    "## Step 07 - Use Generative AI to generate response to our Query (Retrieving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4663cf7b-577e-4bfc-9f2b-d9a024af02f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention, in the context provided, refers to a mechanism in the field of machine learning and, more specifically, in the development of neural network architectures such as the Transformer model. It is a technique that allows the model to focus on different parts of the input data (which can be a sequence of words, for example) when performing a task like translation, summarization, or comprehension.\n",
      "\n",
      "The attention function maps a query and a set of key-value pairs to an output, with all these elements being represented as vectors. The output is computed as a weighted sum, where the weights are determined by the relevance or 'attention' that the model assigns to each input element in relation to the query.\n",
      "\n",
      "Self-attention, or intra-attention, is a specific type of attention mechanism that relates different positions of a single sequence to compute a representation of that sequence. This allows the model to consider the context within the sequence, which is particularly useful for tasks that require an understanding of the relationships between words in a sentence, such as reading comprehension or textual entailment.\n",
      "\n",
      "Multi-Head Attention is an extension of the attention mechanism where the model uses multiple sets of attention heads to capture different types of relationships in the data. Each head can potentially focus on different parts of the sequence, allowing the model to pay attention to various aspects of the information simultaneously.\n",
      "\n",
      "The documents also mention Scaled Dot-Product Attention and Additive Attention, which are two variants of the attention mechanism. Scaled Dot-Product Attention scales the dot products by the inverse square root of the dimension of the key vectors, which helps in stabilizing the gradients during training. Additive Attention uses a feed-forward network with a single hidden layer to compute the compatibility of the query with the keys.\n",
      "\n",
      "Overall, attention mechanisms have significantly improved the performance of neural network models on a wide range of tasks by enabling them to dynamically focus on relevant parts of the input data.\n"
     ]
    }
   ],
   "source": [
    "results = client.query.get(\n",
    "        class_name=\"Chunk\",\n",
    "        properties=[\n",
    "            \"text\",\n",
    "            \"chunk_id\",\n",
    "            \"doc_uuid\",\n",
    "        ]).with_generate(grouped_task = f\"Answer {query} with the provided context\").with_additional(properties=[\"score\"]).with_autocut(2).with_hybrid(query=query,fusion_type=HybridFusion.RELATIVE_SCORE,properties=[\"text\"]).do()\n",
    "\n",
    "print(results[\"data\"][\"Get\"][\"Chunk\"][0][\"_additional\"][\"generate\"][\"groupedResult\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
